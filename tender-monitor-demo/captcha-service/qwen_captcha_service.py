#!/usr/bin/env python3
"""
åŸºäº Qwen2-VL çš„æ™ºèƒ½éªŒè¯ç è¯†åˆ«æœåŠ¡
æ”¯æŒå¤æ‚éªŒè¯ç ã€ç®—æœ¯é¢˜ã€å¸¸è¯†é—®ç­”ç­‰å¤šç§ç±»å‹
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import base64
import io
import os
from PIL import Image
import torch
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# å…¨å±€å˜é‡
model = None
processor = None
device = None

# é…ç½®å‚æ•°
MODEL_NAME = os.getenv("QWEN_MODEL", "Qwen/Qwen2-VL-2B-Instruct")  # å¯é€‰: 2B, 7B, 72B
USE_GPU = os.getenv("USE_GPU", "true").lower() == "true"
MAX_PIXELS = int(os.getenv("MAX_PIXELS", "360000"))  # å›¾ç‰‡æœ€å¤§åƒç´ 
MIN_PIXELS = int(os.getenv("MIN_PIXELS", "64000"))   # å›¾ç‰‡æœ€å°åƒç´ 


def initialize_model():
    """åˆå§‹åŒ– Qwen2-VL æ¨¡å‹"""
    global model, processor, device
    
    logger.info(f"æ­£åœ¨åˆå§‹åŒ– Qwen2-VL æ¨¡å‹: {MODEL_NAME}")
    
    # æ£€æµ‹è®¾å¤‡
    if USE_GPU and torch.cuda.is_available():
        device = "cuda"
        logger.info(f"ä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = "cpu"
        logger.info("ä½¿ç”¨ CPU (å¦‚æœ‰GPUå»ºè®®å¯ç”¨ä»¥æå‡é€Ÿåº¦)")
    
    try:
        # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
        model = Qwen2VLForConditionalGeneration.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            device_map="auto" if device == "cuda" else None,
        )
        
        processor = AutoProcessor.from_pretrained(
            MODEL_NAME,
            min_pixels=MIN_PIXELS,
            max_pixels=MAX_PIXELS
        )
        
        if device == "cpu":
            model = model.to(device)
        
        logger.info("âœ… Qwen2-VL æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        logger.error("è¯·å…ˆä¸‹è½½æ¨¡å‹: huggingface-cli download Qwen/Qwen2-VL-2B-Instruct")
        return False


def recognize_captcha_with_qwen(image_data: bytes, prompt: str = None) -> dict:
    """
    ä½¿ç”¨ Qwen2-VL è¯†åˆ«éªŒè¯ç 
    
    Args:
        image_data: å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
        prompt: è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        dict: {"success": bool, "text": str, "confidence": float, "raw_response": str}
    """
    if model is None or processor is None:
        return {
            "success": False,
            "error": "æ¨¡å‹æœªåˆå§‹åŒ–",
            "text": "",
            "confidence": 0.0
        }
    
    try:
        # åŠ è½½å›¾ç‰‡
        image = Image.open(io.BytesIO(image_data))
        
        # å¦‚æœæ˜¯RGBAè½¬RGB
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        
        # æ„å»ºæç¤ºè¯ï¼ˆæ”¯æŒå¤šç§éªŒè¯ç ç±»å‹ï¼‰
        if prompt is None:
            prompt = """è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„éªŒè¯ç ã€‚
            
è§„åˆ™ï¼š
1. å¦‚æœæ˜¯æ•°å­—/å­—æ¯ç»„åˆï¼Œç›´æ¥è¿”å›å†…å®¹ï¼ˆå¦‚ï¼ša3b9ï¼‰
2. å¦‚æœæ˜¯ç®—æœ¯é¢˜ï¼Œè¿”å›è®¡ç®—ç»“æœï¼ˆå¦‚ï¼š3+5=? è¿”å› 8ï¼‰
3. å¦‚æœæ˜¯æ±‰å­—ï¼Œç›´æ¥è¿”å›æ±‰å­—ï¼ˆå¦‚ï¼šéªŒè¯ç ï¼‰
4. å¦‚æœæ˜¯é—®ç­”é¢˜ï¼Œè¿”å›ç­”æ¡ˆï¼ˆå¦‚ï¼š1+1=? è¿”å› 2ï¼‰
5. åªè¿”å›éªŒè¯ç å†…å®¹ï¼Œä¸è¦ä»»ä½•è§£é‡Š

éªŒè¯ç æ˜¯ï¼š"""
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "image": image,
                    },
                    {"type": "text", "text": prompt},
                ],
            }
        ]
        
        # å‡†å¤‡æ¨ç†
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        image_inputs, video_inputs = process_vision_info(messages)
        
        inputs = processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to(device)
        
        # ç”Ÿæˆç»“æœ
        logger.info("æ­£åœ¨è¿›è¡Œæ¨ç†...")
        with torch.no_grad():
            generated_ids = model.generate(
                **inputs,
                max_new_tokens=128,
                do_sample=False,  # ç¡®å®šæ€§ç”Ÿæˆ
                temperature=0.1,
            )
        
        generated_ids_trimmed = [
            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        
        output_text = processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        # æ¸…ç†è¾“å‡ºï¼ˆå»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œï¼‰
        result_text = output_text.strip()
        
        logger.info(f"è¯†åˆ«æˆåŠŸ: {result_text}")
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        confidence = 0.9 if len(result_text) > 0 else 0.0
        
        return {
            "success": True,
            "text": result_text,
            "confidence": confidence,
            "raw_response": output_text
        }
        
    except Exception as e:
        logger.error(f"è¯†åˆ«å¤±è´¥: {str(e)}", exc_info=True)
        return {
            "success": False,
            "error": str(e),
            "text": "",
            "confidence": 0.0
        }


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    model_status = "ready" if model is not None else "not_initialized"
    
    return jsonify({
        'status': 'ok',
        'service': 'qwen2-vl-captcha',
        'version': '2.0.0',
        'model': MODEL_NAME,
        'device': device if device else 'unknown',
        'model_status': model_status,
        'gpu_available': torch.cuda.is_available()
    })


@app.route('/ocr', methods=['POST'])
def recognize_captcha():
    """
    éªŒè¯ç è¯†åˆ«æ¥å£
    
    æ”¯æŒä¸‰ç§è¯·æ±‚æ–¹å¼ï¼š
    1. multipart/form-data ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ï¼ˆå­—æ®µåï¼šimageï¼‰
    2. application/json ä¼ é€’ base64 ç¼–ç çš„å›¾ç‰‡ï¼ˆå­—æ®µåï¼šimage_base64ï¼‰
    3. ç›´æ¥ä¼ é€’å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®ï¼ˆContent-Type: image/png æˆ– image/jpegï¼‰
    
    å¯é€‰å‚æ•°ï¼š
    - prompt: è‡ªå®šä¹‰æç¤ºè¯ï¼ˆç”¨äºç‰¹æ®ŠéªŒè¯ç ç±»å‹ï¼‰
    
    è¿”å›æ ¼å¼ï¼š
    {
        "success": true,
        "text": "è¯†åˆ«ç»“æœ",
        "confidence": 0.95,
        "raw_response": "æ¨¡å‹åŸå§‹è¾“å‡º"
    }
    """
    if model is None:
        return jsonify({
            'success': False,
            'error': 'æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆå¯åŠ¨æ¨¡å‹'
        }), 503
    
    try:
        image_data = None
        custom_prompt = None
        
        # æ–¹å¼1ï¼šæ¥æ”¶æ–‡ä»¶ä¸Šä¼ 
        if 'image' in request.files:
            file = request.files['image']
            image_data = file.read()
            custom_prompt = request.form.get('prompt')
            logger.info(f"æ¥æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ ï¼Œå¤§å°ï¼š{len(image_data)} å­—èŠ‚")
        
        # æ–¹å¼2ï¼šæ¥æ”¶ base64 ç¼–ç 
        elif request.is_json:
            json_data = request.json
            if 'image_base64' in json_data:
                base64_str = json_data['image_base64']
                # ç§»é™¤å¯èƒ½çš„ data:image/png;base64, å‰ç¼€
                if ',' in base64_str:
                    base64_str = base64_str.split(',')[1]
                image_data = base64.b64decode(base64_str)
                custom_prompt = json_data.get('prompt')
                logger.info(f"æ¥æ”¶åˆ° base64 æ•°æ®ï¼Œè§£ç åå¤§å°ï¼š{len(image_data)} å­—èŠ‚")
        
        # æ–¹å¼3ï¼šæ¥æ”¶åŸå§‹äºŒè¿›åˆ¶æ•°æ®
        elif request.content_type and 'image' in request.content_type:
            image_data = request.get_data()
            logger.info(f"æ¥æ”¶åˆ°åŸå§‹å›¾ç‰‡æ•°æ®ï¼Œå¤§å°ï¼š{len(image_data)} å­—èŠ‚")
        
        if not image_data:
            logger.warning("è¯·æ±‚ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®")
            return jsonify({
                'success': False,
                'error': 'æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®'
            }), 400
        
        # æ‰§è¡Œè¯†åˆ«
        result = recognize_captcha_with_qwen(image_data, custom_prompt)
        
        if result['success']:
            return jsonify(result)
        else:
            return jsonify(result), 500
    
    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥ï¼š{str(e)}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/batch-ocr', methods=['POST'])
def batch_recognize():
    """æ‰¹é‡è¯†åˆ«æ¥å£"""
    if model is None:
        return jsonify({
            'success': False,
            'error': 'æ¨¡å‹æœªåˆå§‹åŒ–'
        }), 503
    
    try:
        if 'images' not in request.files:
            return jsonify({
                'success': False,
                'error': 'è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ï¼ˆå­—æ®µåï¼šimagesï¼Œæ”¯æŒå¤šæ–‡ä»¶ï¼‰'
            }), 400
        
        files = request.files.getlist('images')
        results = []
        
        for file in files:
            image_data = file.read()
            result = recognize_captcha_with_qwen(image_data)
            results.append({
                'filename': file.filename,
                'text': result.get('text', ''),
                'confidence': result.get('confidence', 0.0),
                'success': result.get('success', False)
            })
        
        logger.info(f"æ‰¹é‡è¯†åˆ«å®Œæˆï¼Œå…± {len(results)} å¼ å›¾ç‰‡")
        
        return jsonify({
            'success': True,
            'count': len(results),
            'results': results
        })
    
    except Exception as e:
        logger.error(f"æ‰¹é‡è¯†åˆ«å¤±è´¥ï¼š{str(e)}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


if __name__ == '__main__':
    print("\n" + "="*70)
    print("ğŸš€ Qwen2-VL æ™ºèƒ½éªŒè¯ç è¯†åˆ«æœåŠ¡")
    print("="*70)
    
    # åˆå§‹åŒ–æ¨¡å‹
    if not initialize_model():
        print("\nâŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼ŒæœåŠ¡æ— æ³•å¯åŠ¨")
        print("\nè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š")
        print("1. å®‰è£…ä¾èµ–: pip install -r requirements_qwen.txt")
        print("2. ä¸‹è½½æ¨¡å‹: huggingface-cli download Qwen/Qwen2-VL-2B-Instruct")
        print("3. å¦‚æœä¸‹è½½æ…¢ï¼Œå¯ä½¿ç”¨é•œåƒ: export HF_ENDPOINT=https://hf-mirror.com")
        exit(1)
    
    print(f"\nâœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"ğŸ“¦ æ¨¡å‹: {MODEL_NAME}")
    print(f"ğŸ’» è®¾å¤‡: {device}")
    print(f"ğŸŒ æœåŠ¡åœ°å€: http://localhost:5000")
    print(f"â¤ï¸  å¥åº·æ£€æŸ¥: http://localhost:5000/health")
    print(f"ğŸ” è¯†åˆ«æ¥å£: POST http://localhost:5000/ocr")
    print("="*70 + "\n")
    
    # å¯åŠ¨æœåŠ¡
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False,
        threaded=False  # Qwen2-VL å»ºè®®å•çº¿ç¨‹
    )
